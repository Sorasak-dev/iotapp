import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import make_scorer, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
from data_generator import SensorDataGenerator
from anomaly_models import AnomalyDetectionModels, RuleBasedAnomalyDetector
import os
import warnings
import logging
from datetime import datetime
import json
from sklearn.utils.class_weight import compute_class_weight

warnings.filterwarnings('ignore')

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def clean_infinity_and_extreme_values(df):
    """Clean infinity and extreme values thoroughly"""
    print("‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ñ‡πà‡∏≤ infinity ‡πÅ‡∏•‡∏∞ extreme values...")
    
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    cleaned_count = 0
    
    for col in numeric_columns:
        if col in df.columns:
            # Replace infinity with NaN
            infinity_mask = np.isinf(df[col])
            if infinity_mask.any():
                df.loc[infinity_mask, col] = np.nan
                cleaned_count += infinity_mask.sum()
                logger.info(f"‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà {infinity_mask.sum()} ‡∏Ñ‡πà‡∏≤ infinity ‡πÉ‡∏ô {col}")
            
            # Define safe ranges for sensor data
            safe_ranges = {
                'temperature': (-50, 80),
                'humidity': (0, 100),
                'voltage': (0, 6),
                'battery_level': (0, 100),
                'co2': (0, 5000),
                'ec': (0, 10),
                'ph': (0, 14),
                'vpd': (0, 20),
                'dew_point': (-50, 60)
            }
            
            if col in safe_ranges:
                min_val, max_val = safe_ranges[col]
                extreme_mask = (df[col] < min_val) | (df[col] > max_val)
                
                if extreme_mask.any():
                    df.loc[extreme_mask, col] = np.nan
                    logger.info(f"‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà {extreme_mask.sum()} ‡∏Ñ‡πà‡∏≤ extreme ‡πÉ‡∏ô {col}")
            
            # Replace values too large for float32
            float32_max = np.finfo(np.float32).max / 100  # Use 1/100 for safety
            too_large_mask = np.abs(df[col].fillna(0)) > float32_max
            
            if too_large_mask.any():
                df.loc[too_large_mask, col] = np.nan
                logger.info(f"‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà {too_large_mask.sum()} ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡πÉ‡∏ô {col}")
    
    logger.info(f"Data cleaning completed: {cleaned_count} values processed")
    return df

def load_or_generate_data(force_generate=False):
    """Load or generate high-quality data with enhanced cleaning"""
    data_file = "data/sensor_training_data.csv"
    
    if os.path.exists(data_file) and not force_generate:
        print("‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå...")
        df = pd.read_csv(data_file)
        logger.info(f"‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå: {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    else:
        print("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà...")
        generator = SensorDataGenerator()
        df = generator.generate_comprehensive_dataset_enhanced(
            days=100,           # Reduced for stability
            normal_ratio=0.75   # 75:25 ratio for better balance
        )
        generator.save_dataset(df, "sensor_training_data.csv")
        logger.info(f"‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà: {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    
    # Clean data before return
    df = clean_infinity_and_extreme_values(df)
    
    return df

def validate_data_quality(df):
    """Enhanced data quality validation"""
    print("\n‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    
    quality_score = 0
    
    # Check missing data
    missing_data = df.isnull().sum()
    if missing_data.sum() > 0:
        print("‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ:")
        for col, missing in missing_data.items():
            if missing > 0:
                print(f"  {col}: {missing} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ({missing/len(df)*100:.1f}%)")
    else:
        print("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏≤‡∏¢‡πÑ‡∏õ ‚úì")
        quality_score += 1
    
    # Check for infinity and extreme values
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    infinity_found = False
    extreme_found = False
    
    for col in numeric_columns:
        if np.isinf(df[col]).any():
            infinity_found = True
            print(f"‚ö†Ô∏è  ‡∏û‡∏ö‡∏Ñ‡πà‡∏≤ infinity ‡πÉ‡∏ô {col}")
        
        if (np.abs(df[col].fillna(0)) > 1e6).any():
            extreme_found = True
            print(f"‚ö†Ô∏è  ‡∏û‡∏ö‡∏Ñ‡πà‡∏≤ extreme ‡πÉ‡∏ô {col}")
    
    if not infinity_found and not extreme_found:
        print("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡πà‡∏≤ infinity ‡∏´‡∏£‡∏∑‡∏≠ extreme values ‚úì")
        quality_score += 2
    
    # Check anomaly ratio
    anomaly_ratio = len(df[df['is_anomaly'] == 1]) / len(df)
    print(f"\n‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥: {anomaly_ratio:.1%}")
    
    if 0.20 <= anomaly_ratio <= 0.30:
        print("‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‚úì")
        quality_score += 2
    elif 0.15 <= anomaly_ratio < 0.20 or 0.30 < anomaly_ratio <= 0.35:
        print("‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ ‚ö†Ô∏è")
        quality_score += 1
    else:
        logger.warning("‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°")
    
    data_quality_ok = quality_score >= 3
    
    if data_quality_ok:
        print(f"\n‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏µ ‚úì (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {quality_score}/5)")
    else:
        logger.warning(f"‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {quality_score}/5)")
    
    return data_quality_ok

def safe_preprocessing_check(X, stage_name=""):
    """Check data safety before processing"""
    if len(stage_name) > 0:
        print(f"‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {stage_name}...")
    
    # Check NaN
    nan_count = np.isnan(X).sum()
    if nan_count > 0:
        logger.warning(f"‡∏û‡∏ö NaN {nan_count} ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô {stage_name}")
    
    # Check Infinity
    inf_count = np.isinf(X).sum()
    if inf_count > 0:
        logger.error(f"‡∏û‡∏ö Infinity {inf_count} ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô {stage_name}")
        return False
    
    # Check values too large for float32
    float32_max = np.finfo(np.float32).max / 1000
    too_large = (np.abs(X) > float32_max).sum()
    if too_large > 0:
        logger.error(f"‡∏û‡∏ö‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ {too_large} ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô {stage_name}")
        return False
    
    logger.info(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {stage_name} ‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ ‚úì")
    return True

def prepare_training_data(df):
    """Prepare data for training with enhanced safety"""
    print("\n‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô...")
    
    # Remove rows with missing essential data
    essential_cols = ['temperature', 'humidity', 'voltage']
    before_len = len(df)
    df_clean = df.dropna(subset=essential_cols)
    after_len = len(df_clean)
    
    if before_len != after_len:
        logger.info(f"‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå: {before_len - after_len} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    
    # Clean data again after removing rows
    df_clean = clean_infinity_and_extreme_values(df_clean)
    
    # Balance data
    anomaly_count = len(df_clean[df_clean['is_anomaly'] == 1])
    normal_count = len(df_clean[df_clean['is_anomaly'] == 0])
    
    print(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏î‡∏∏‡∏• - ‡∏õ‡∏Å‡∏ï‡∏¥: {normal_count}, ‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥: {anomaly_count}")
    
    # Target ratio 75:25 for stability
    target_ratio = 3.0  # 75% normal, 25% anomaly
    current_ratio = normal_count / anomaly_count if anomaly_count > 0 else float('inf')
    
    if current_ratio > target_ratio * 1.2:
        normal_data = df_clean[df_clean['is_anomaly'] == 0]
        target_normal_count = int(anomaly_count * target_ratio)
        
        if target_normal_count < normal_count and target_normal_count > 0:
            normal_sample = normal_data.sample(n=target_normal_count, random_state=42)
            anomaly_data = df_clean[df_clean['is_anomaly'] == 1]
            df_clean = pd.concat([normal_sample, anomaly_data], ignore_index=True)
            
            logger.info(f"‡∏õ‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô 75:25 - ‡∏õ‡∏Å‡∏ï‡∏¥: {target_normal_count}, ‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥: {anomaly_count}")
    
    final_normal = len(df_clean[df_clean['is_anomaly'] == 0])
    final_anomaly = len(df_clean[df_clean['is_anomaly'] == 1])
    
    print(f"‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ - ‡∏õ‡∏Å‡∏ï‡∏¥: {final_normal}, ‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥: {final_anomaly}")
    
    # Shuffle data
    df_final = df_clean.sample(frac=1, random_state=42).reset_index(drop=True)
    
    # Final safety check
    df_final = clean_infinity_and_extreme_values(df_final)
    
    logger.info(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢: {len(df_final)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    return df_final

def hyperparameter_optimization(X_train, y_train, anomaly_detector):
    """Optimize hyperparameters automatically"""
    print("\n‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á hyperparameters...")
    
    # Check data safety
    if not safe_preprocessing_check(X_train, "training data"):
        logger.error("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏°‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ - ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á")
        return {}
    
    # Calculate class weights and contamination
    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
    contamination = len(y_train[y_train == 1]) / len(y_train)
    
    logger.info(f"Class weights: {dict(zip(np.unique(y_train), class_weights))}")
    logger.info(f"Contamination rate: {contamination:.3f}")
    
    # Optimize parameters for data quality
    optimized_params = {
        'isolation_forest': {
            'n_estimators': 200,        # Conservative for stability
            'max_samples': min(0.7, max(0.3, len(X_train) / 2000)),
            'contamination': min(0.30, max(0.10, contamination * 0.9)),
            'max_features': 0.8,
            'bootstrap': False,
            'random_state': 42
        },
        'one_class_svm': {
            'nu': min(0.30, max(0.10, contamination * 0.8)),
            'gamma': 'scale',
            'kernel': 'rbf',
            'shrinking': True,
            'tol': 1e-3
        }
    }
    
    logger.info(f"‡πÉ‡∏ä‡πâ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß: {optimized_params}")
    return optimized_params

def train_and_evaluate_models(df):
    """Train and evaluate models with enhanced error handling"""
    print("\n‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
    
    # Prepare data
    anomaly_detector = AnomalyDetectionModels()
    
    try:
        df_prepared, feature_columns = anomaly_detector.prepare_data(df)
        
        if len(feature_columns) == 0:
            raise ValueError("‡πÑ‡∏°‡πà‡∏°‡∏µ features ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ")
        
        logger.info(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô features: {len(feature_columns)}")
        
    except Exception as e:
        logger.error(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
        raise
    
    # Extract features and labels
    X = df_prepared[feature_columns].values
    y = df_prepared['is_anomaly'].values
    
    # Clean features data
    print("‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î features...")
    X = np.where(np.isnan(X), 0, X)
    X = np.where(np.isinf(X), 0, X)
    
    # Clip values to safe range
    safe_max = np.finfo(np.float32).max / 1000
    X = np.clip(X, -safe_max, safe_max)
    
    # Final safety check
    if not safe_preprocessing_check(X, "processed features"):
        raise ValueError("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• features ‡πÑ‡∏°‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô")
    
    print(f"Features: {len(feature_columns)} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå")
    print(f"‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {X.shape}")
    print(f"‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏≤ features: {X.min():.3f} ‡∏ñ‡∏∂‡∏á {X.max():.3f}")
    
    # Split data
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, test_size=0.20, random_state=42, stratify=y
    )
    
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=0.20, random_state=42, stratify=y_temp
    )
    
    print(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô: {len(X_train)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    print(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• validation: {len(X_val)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    print(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö: {len(X_test)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    print(f"  - ‡∏õ‡∏Å‡∏ï‡∏¥: {len(y_test[y_test == 0])}")
    print(f"  - ‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥: {len(y_test[y_test == 1])}")
    
    # Optimize hyperparameters
    best_params = hyperparameter_optimization(X_train, y_train, anomaly_detector)
    
    results = {}
    
    # Train models with enhanced error handling
    models_to_train = [
        ('one_class_svm', 'One-Class SVM'),
        ('local_outlier_factor', 'Local Outlier Factor'),
        ('elliptic_envelope', 'Elliptic Envelope'),
        ('isolation_forest', 'Isolation Forest'),
        ('ensemble', 'Ensemble Model')
    ]
    
    successful_models = []
    
    for model_name, model_display_name in models_to_train:
        try:
            print(f"\n‡πÄ‡∏ó‡∏£‡∏ô {model_display_name}...")
            
            # Update parameters
            if model_name in best_params:
                if hasattr(anomaly_detector, 'model_config'):
                    anomaly_detector.model_config[model_name].update(best_params[model_name])
            
            # Train model
            if model_name == 'isolation_forest':
                anomaly_detector.train_isolation_forest_enhanced(X_train, y_train)
            elif model_name == 'one_class_svm':
                anomaly_detector.train_one_class_svm_enhanced(X_train, y_train)
            elif model_name == 'local_outlier_factor':
                anomaly_detector.train_local_outlier_factor(X_train, y_train)
            elif model_name == 'elliptic_envelope':
                anomaly_detector.train_elliptic_envelope(X_train, y_train)
            elif model_name == 'ensemble':
                anomaly_detector.train_ensemble_model(X_train, y_train)
            
            # Evaluate model
            val_results = anomaly_detector.evaluate_model_enhanced(X_val, y_val, model_name)
            test_results = anomaly_detector.evaluate_model_enhanced(X_test, y_test, model_name)
            
            # Check results
            val_f1 = val_results.get('f1_score', 0)
            test_f1 = test_results.get('f1_score', 0)
            
            if val_f1 > 0.1 and test_f1 > 0.1:  # Model works
                results[model_name] = {
                    'validation': val_results,
                    'test': test_results,
                    'best_params': best_params.get(model_name, {})
                }
                successful_models.append(model_name)
                
                logger.info(f"{model_display_name} ‡πÄ‡∏ó‡∏£‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                logger.info(f"Validation F1: {val_f1:.4f}")
                logger.info(f"Test F1: {test_f1:.4f}")
            else:
                logger.warning(f"{model_display_name} F1-score ‡∏ï‡πà‡∏≥")
                
        except Exception as e:
            logger.error(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô {model_display_name}: {e}")
            continue
    
    if len(successful_models) == 0:
        logger.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ ‡πÅ‡∏ï‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ")
        # Return available results even if not perfect
        return results, anomaly_detector
    
    print(f"\n‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(successful_models)} ‡πÇ‡∏°‡πÄ‡∏î‡∏•")
    print(f"‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {', '.join(successful_models)}")
    
    # Save models
    print("\n‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
    anomaly_detector.save_models_enhanced("models/anomaly_detection")
    logger.info("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
    
    return results, anomaly_detector

def test_rule_based_detection():
    """Test Rule-based Detection"""
    print("\n‡∏ó‡∏î‡∏™‡∏≠‡∏ö Rule-based Anomaly Detection...")
    
    rule_detector = RuleBasedAnomalyDetector()
    
    test_cases = [
        {
            'name': '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á',
            'data': {
                'temperature': 25.5,
                'humidity': 64.2,
                'vpd': 1.18,
                'dew_point': 17.8,
                'voltage': 3.31,
                'battery_level': 84,
                'co2': 785,
                'ec': 1.52,
                'ph': 6.48,
                'timestamp': datetime.now().isoformat()
            }
        },
        {
            'name': '‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏™‡∏π‡∏á',
            'data': {
                'temperature': 17.5,
                'humidity': 97.0,
                'vpd': 0.25,
                'dew_point': 17.2,
                'voltage': 3.25,
                'battery_level': 78,
                'timestamp': datetime.now().isoformat()
            }
        },
        {
            'name': '‡πÄ‡∏ã‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÄ‡∏™‡∏µ‡∏¢',
            'data': {
                'temperature': -999,
                'humidity': 0,
                'voltage': 0,
                'battery_level': 0,
                'co2': -999,
                'timestamp': datetime.now().isoformat()
            }
        }
    ]
    
    for test_case in test_cases:
        print(f"\n‡∏ó‡∏î‡∏™‡∏≠‡∏ö: {test_case['name']}")
        
        try:
            anomalies = rule_detector.detect_anomalies([test_case['data']])
            
            if anomalies:
                print("‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥:")
                for anomaly in anomalies[:2]:
                    alert_icon = "üî¥" if anomaly['alert_level'] == 'red' else "‚ö†Ô∏è"
                    print(f"  {alert_icon} {anomaly['type']}: {anomaly['message']}")
            else:
                print("‚úÖ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥")
        except Exception as e:
            logger.error(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö {test_case['name']}: {e}")
    
    logger.info("‡∏ó‡∏î‡∏™‡∏≠‡∏ö Rule-based Detection ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")

def create_performance_visualization(results):
    """Create performance visualization"""
    if not results:
        print("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü")
        return
    
    try:
        print("\n‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û...")
        
        os.makedirs("plots", exist_ok=True)
        
        plt.style.use('default')
        plt.rcParams['font.size'] = 10
        plt.rcParams['figure.facecolor'] = 'white'
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Model Performance Analysis v2.1', fontsize=16, fontweight='bold')
        
        models = list(results.keys())
        
        # Prepare metrics data
        metrics = {
            'F1-Score': [],
            'Precision': [],
            'Recall': [],
            'Accuracy': []
        }
        
        for model in models:
            try:
                test_result = results[model]['test']
                
                f1 = test_result.get('f1_score', 0)
                precision = test_result.get('precision', 0)
                recall = test_result.get('recall', 0)
                
                # Calculate accuracy from confusion matrix if available
                cm = test_result.get('confusion_matrix')
                if cm is not None and cm.size >= 4:
                    tn, fp, fn, tp = cm.ravel()
                    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0
                else:
                    accuracy = 0
                
                metrics['F1-Score'].append(f1)
                metrics['Precision'].append(precision)
                metrics['Recall'].append(recall)
                metrics['Accuracy'].append(accuracy)
                
            except Exception as e:
                logger.warning(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {model}: {e}")
                for metric in metrics.keys():
                    metrics[metric].append(0)
        
        # Create plots
        colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']
        
        for i, (metric_name, values) in enumerate(metrics.items()):
            row, col = i // 2, i % 2
            ax = axes[row, col]
            
            bars = ax.bar(models, values, color=colors[i], alpha=0.7, edgecolor='black', linewidth=0.5)
            ax.set_title(f'{metric_name}', fontweight='bold')
            ax.set_ylabel(metric_name)
            ax.set_ylim(0, 1.05)
            ax.tick_params(axis='x', rotation=45)
            ax.grid(axis='y', alpha=0.3)
            
            # Add values on bars
            for j, (bar, value) in enumerate(zip(bars, values)):
                if value > 0:
                    ax.text(bar.get_x() + bar.get_width()/2, value + 0.02, 
                           f'{value:.3f}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('plots/model_performance_v21.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("‡∏Å‡∏£‡∏≤‡∏ü‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà: plots/model_performance_v21.png")
        logger.info("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        
    except Exception as e:
        logger.error(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü: {e}")

def display_results_summary(results):
    """Display enhanced results summary"""
    print("\n" + "="*80)
    print("‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Enhanced v2.1")
    print("="*80)
    
    if not results:
        print("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô")
        return
    
    best_f1 = 0
    best_model = None
    
    for model_name, result in results.items():
        try:
            test_result = result['test']
            val_result = result['validation']
            
            test_f1 = test_result.get('f1_score', 0)
            test_precision = test_result.get('precision', 0)
            test_recall = test_result.get('recall', 0)
            test_specificity = test_result.get('specificity', 0)
            
            val_f1 = val_result.get('f1_score', 0)
            
            if test_f1 > best_f1:
                best_f1 = test_f1
                best_model = model_name
            
            overfitting_score = abs(val_f1 - test_f1)
            overfitting_status = "Low" if overfitting_score < 0.05 else "Medium" if overfitting_score < 0.1 else "High"
            
            print(f"\n{model_name.replace('_', ' ').upper()}:")
            print(f"  - Test F1-Score: {test_f1:.4f}")
            print(f"  - Test Precision: {test_precision:.4f}")
            print(f"  - Test Recall: {test_recall:.4f}")
            print(f"  - Test Specificity: {test_specificity:.4f}")
            print(f"  - Validation F1: {val_f1:.4f}")
            print(f"  - Overfitting: {overfitting_status} ({overfitting_score:.4f})")
            
            if 'best_params' in result and result['best_params']:
                print(f"  - Parameters: {result['best_params']}")
                
        except Exception as e:
            logger.error(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• {model_name}: {e}")
            continue
    
    print(f"\n‡∏™‡∏£‡∏∏‡∏õ:")
    if best_model and best_f1 > 0:
        print(f"  - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {best_model.replace('_', ' ').title()}")
        print(f"  - F1-Score: {best_f1:.4f}")
        
        if best_f1 > 0.7:
            print("  - ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏î‡∏µ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        elif best_f1 > 0.5:
            print("  - ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ")
        else:
            print("  - ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏ï‡πà‡∏≥ ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•")
    else:
        print("  - ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ä‡πâ Rule-based Detection")

def save_training_info(results, detector):
    """Save training information"""
    try:
        training_summary = {
            'training_date': datetime.now().isoformat(),
            'model_type': 'anomaly_detection_v2.1_fixed',
            'total_models': len(results),
            'successful_models': len([r for r in results.values() if r['test'].get('f1_score', 0) > 0.1]),
            'best_model': '',
            'best_test_f1_score': 0,
            'model_performance': {},
            'feature_info': {
                'total_features': len(getattr(detector, 'feature_columns', []) + 
                                    getattr(detector, 'time_features', []) + 
                                    getattr(detector, 'derived_features', [])),
                'base_features': len(getattr(detector, 'feature_columns', [])),
                'derived_features': len(getattr(detector, 'derived_features', []))
            },
            'training_config': {
                'data_ratio': '75% normal, 25% anomaly',
                'data_splitting': '64% train, 16% validation, 20% test',
                'data_cleaning': 'enhanced infinity/extreme value handling',
                'safety_checks': 'comprehensive preprocessing validation'
            }
        }
        
        # Find best model
        for model_name, result in results.items():
            try:
                test_result = result['test']
                test_f1 = test_result.get('f1_score', 0)
                
                training_summary['model_performance'][model_name] = {
                    'test_f1_score': test_f1,
                    'test_precision': test_result.get('precision', 0),
                    'test_recall': test_result.get('recall', 0),
                    'test_specificity': test_result.get('specificity', 0)
                }
                
                if test_f1 > training_summary['best_test_f1_score']:
                    training_summary['best_test_f1_score'] = test_f1
                    training_summary['best_model'] = model_name
                    
            except Exception as e:
                logger.error(f"Error processing {model_name}: {e}")
                continue
        
        # Save to file
        os.makedirs('models', exist_ok=True)
        with open('models/training_summary_v21.json', 'w', encoding='utf-8') as f:
            json.dump(training_summary, f, indent=2, ensure_ascii=False)
        
        logger.info("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô v2.1 ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        
    except Exception as e:
        logger.error(f"Error saving training info: {e}")

def main():
    """Main training function - Enhanced v2.1"""
    print("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Anomaly Detection Enhanced v2.1 (Fixed)")
    print("="*80)
    
    # Create directories
    for directory in ["data", "models", "plots"]:
        os.makedirs(directory, exist_ok=True)
    
    try:
        # 1. Load and clean data
        print("\n[1/6] ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        df = load_or_generate_data(force_generate=True)
        
        # 2. Validate data quality
        print("\n[2/6] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        data_quality_ok = validate_data_quality(df)
        if not data_quality_ok:
            logger.warning("‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÅ‡∏ï‡πà‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠")
        
        # 3. Prepare training data
        print("\n[3/6] ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô...")
        df_clean = prepare_training_data(df)
        
        if len(df_clean) < 100:
            raise ValueError("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô")
        
        # 4. Train and evaluate models
        print("\n[4/6] ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
        results, detector = train_and_evaluate_models(df_clean)
        
        # 5. Test rule-based detection
        print("\n[5/6] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Rule-based Detection...")
        test_rule_based_detection()
        
        # 6. Create visualization and summary
        print("\n[6/6] ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•...")
        create_performance_visualization(results)
        display_results_summary(results)
        save_training_info(results, detector)
        
        print(f"\n{'='*80}")
        print("‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Enhanced v2.1 (Fixed) ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
        print("‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á:")
        print("  - models/anomaly_detection_*.pkl (‡πÇ‡∏°‡πÄ‡∏î‡∏• ML)")
        print("  - models/training_summary_v21.json (‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô)")
        print("  - data/sensor_training_data.csv (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô)")
        print("  - plots/model_performance_v21.png (‡∏Å‡∏£‡∏≤‡∏ü‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û)")
        print("  - training.log (‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô)")
        
        # Show final summary
        if results:
            working_models = [k for k, v in results.items() if v['test'].get('f1_score', 0) > 0.1]
            
            if working_models:
                best_model = max(working_models, 
                               key=lambda x: results[x]['test'].get('f1_score', 0))
                best_f1 = results[best_model]['test'].get('f1_score', 0)
                
                print(f"\n‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {best_model.replace('_', ' ').title()}")
                print(f"Test F1-Score: {best_f1:.4f}")
                print(f"‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ: {len(working_models)}/{len(results)}")
            else:
                print("\n‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏• ML ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ")
                print("‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ä‡πâ Rule-based Detection ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
        
        logger.info("‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Enhanced v2.1 (Fixed) ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå")
        
        return detector, results
        
    except Exception as e:
        logger.error(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô: {e}")
        print(f"\n‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        print("‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:")
        print("  1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• input")
        print("  2. ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏≥‡∏ô‡∏ß‡∏ô features")
        print("  3. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö memory ‡πÅ‡∏•‡∏∞ system resources")
        print("  4. ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Rule-based detection")
        raise

if __name__ == "__main__":
    try:
        detector, results = main()
        
        # Final statistics
        if results:
            working_models = [k for k, v in results.items() if v['test'].get('f1_score', 0) > 0.1]
            print(f"\n‡∏™‡∏£‡∏∏‡∏õ: ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ {len(working_models)} ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å {len(results)} ‡πÇ‡∏°‡πÄ‡∏î‡∏•")
            
            if working_models:
                avg_f1 = np.mean([results[m]['test'].get('f1_score', 0) for m in working_models])
                print(f"F1-Score ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {avg_f1:.4f}")
                print("‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            else:
                print("‡πÉ‡∏ä‡πâ Rule-based detection ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
        else:
            print("‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à - ‡πÉ‡∏ä‡πâ Rule-based detection")
            
    except KeyboardInterrupt:
        print("\n‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏ñ‡∏π‡∏Å‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡πÇ‡∏î‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ")
        logger.info("Training interrupted by user")
    except Exception as e:
        print(f"\n‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")
        logger.error(f"Training failed: {e}")
        print("\n‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: python anomaly_api.py ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö Rule-based detection")