import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import make_scorer, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
from data_generator import SensorDataGenerator
from anomaly_models import AnomalyDetectionModels, RuleBasedAnomalyDetector
import os
import warnings
import logging
from datetime import datetime
import json
from sklearn.utils.class_weight import compute_class_weight

warnings.filterwarnings('ignore')

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def clean_infinity_and_extreme_values(df):
    """Clean infinity and extreme values thoroughly"""
    print("üßπ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    cleaned_count = 0
    
    for col in numeric_columns:
        if col in df.columns:
            # Replace infinity with NaN
            infinity_mask = np.isinf(df[col])
            if infinity_mask.any():
                df.loc[infinity_mask, col] = np.nan
                cleaned_count += infinity_mask.sum()
                logger.info(f"‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà {infinity_mask.sum()} ‡∏Ñ‡πà‡∏≤ infinity ‡πÉ‡∏ô {col}")
            
            # Define safe ranges for sensor data
            safe_ranges = {
                'temperature': (-50, 80),
                'humidity': (0, 100),
                'voltage': (0, 6),
                'battery_level': (0, 100),
                'co2': (0, 5000),
                'ec': (0, 10),
                'ph': (0, 14),
                'vpd': (0, 20),
                'dew_point': (-50, 60)
            }
            
            if col in safe_ranges:
                min_val, max_val = safe_ranges[col]
                extreme_mask = (df[col] < min_val) | (df[col] > max_val)
                
                if extreme_mask.any():
                    df.loc[extreme_mask, col] = np.nan
                    logger.info(f"‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà {extreme_mask.sum()} ‡∏Ñ‡πà‡∏≤ extreme ‡πÉ‡∏ô {col}")
            
            # Replace values too large for float32
            float32_max = np.finfo(np.float32).max / 100
            too_large_mask = np.abs(df[col].fillna(0)) > float32_max
            
            if too_large_mask.any():
                df.loc[too_large_mask, col] = np.nan
                logger.info(f"‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà {too_large_mask.sum()} ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡πÉ‡∏ô {col}")
    
    logger.info(f"‚úÖ Data cleaning completed: {cleaned_count} values processed")
    return df

def load_or_generate_data(force_generate=False):
    """Load or generate high-quality data with proper anomaly ratio"""
    data_file = "data/sensor_training_data.csv"
    
    if os.path.exists(data_file) and not force_generate:
        print("üìÇ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå...")
        df = pd.read_csv(data_file)
        logger.info(f"‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå: {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    else:
        print("üî® ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ 1-2 ‡∏ô‡∏≤‡∏ó‡∏µ)...")
        generator = SensorDataGenerator()
        df = generator.generate_comprehensive_dataset_enhanced(
            days=365,           # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏õ‡πá‡∏ô 1 ‡∏õ‡∏µ
            normal_ratio=0.92   # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô 92:8 (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö anomaly detection)
        )
        generator.save_dataset(df, "sensor_training_data.csv")
        logger.info(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà: {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    
    # Clean data before return
    df = clean_infinity_and_extreme_values(df)
    
    return df

def validate_data_quality(df):
    """Enhanced data quality validation"""
    print("\nüîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    
    quality_score = 0
    
    # Check missing data
    missing_data = df.isnull().sum()
    if missing_data.sum() > 0:
        print("‚ö†Ô∏è  ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ:")
        for col, missing in missing_data.items():
            if missing > 0:
                print(f"     {col}: {missing} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ({missing/len(df)*100:.1f}%)")
    else:
        print("‚úÖ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏≤‡∏¢‡πÑ‡∏õ")
        quality_score += 1
    
    # Check for infinity and extreme values
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    infinity_found = False
    extreme_found = False
    
    for col in numeric_columns:
        if np.isinf(df[col]).any():
            infinity_found = True
            print(f"‚ö†Ô∏è  ‡∏û‡∏ö‡∏Ñ‡πà‡∏≤ infinity ‡πÉ‡∏ô {col}")
        
        if (np.abs(df[col].fillna(0)) > 1e6).any():
            extreme_found = True
            print(f"‚ö†Ô∏è  ‡∏û‡∏ö‡∏Ñ‡πà‡∏≤ extreme ‡πÉ‡∏ô {col}")
    
    if not infinity_found and not extreme_found:
        print("‚úÖ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡πà‡∏≤ infinity ‡∏´‡∏£‡∏∑‡∏≠ extreme values")
        quality_score += 2
    
    # Check anomaly ratio
    anomaly_ratio = len(df[df['is_anomaly'] == 1]) / len(df)
    print(f"\nüìä ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥: {anomaly_ratio:.1%}")
    
    if 0.05 <= anomaly_ratio <= 0.15:
        print("‚úÖ ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Anomaly Detection")
        quality_score += 2
    elif 0.15 < anomaly_ratio <= 0.25:
        print("‚ö†Ô∏è  ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏π‡∏á‡πÑ‡∏õ‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡πÅ‡∏ï‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ")
        quality_score += 1
    else:
        logger.warning("‚ùå ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°")
    
    data_quality_ok = quality_score >= 3
    
    if data_quality_ok:
        print(f"\n‚úÖ ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏µ (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {quality_score}/5)")
    else:
        logger.warning(f"‚ö†Ô∏è  ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {quality_score}/5)")
    
    return data_quality_ok

def safe_preprocessing_check(X, stage_name=""):
    """Check data safety before processing"""
    if len(stage_name) > 0:
        logger.info(f"üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {stage_name}...")
    
    # Check NaN
    nan_count = np.isnan(X).sum()
    if nan_count > 0:
        logger.warning(f"‡∏û‡∏ö NaN {nan_count} ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô {stage_name}")
    
    # Check Infinity
    inf_count = np.isinf(X).sum()
    if inf_count > 0:
        logger.error(f"‚ùå ‡∏û‡∏ö Infinity {inf_count} ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô {stage_name}")
        return False
    
    # Check values too large for float32
    float32_max = np.finfo(np.float32).max / 1000
    too_large = (np.abs(X) > float32_max).sum()
    if too_large > 0:
        logger.error(f"‚ùå ‡∏û‡∏ö‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ {too_large} ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô {stage_name}")
        return False
    
    logger.info(f"‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {stage_name} ‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢")
    return True

def prepare_training_data(df):
    """Prepare data for training with proper anomaly ratio"""
    print("\n‚öôÔ∏è  ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô...")
    
    # Remove rows with missing essential data
    essential_cols = ['temperature', 'humidity', 'voltage']
    before_len = len(df)
    df_clean = df.dropna(subset=essential_cols)
    after_len = len(df_clean)
    
    if before_len != after_len:
        logger.info(f"‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå: {before_len - after_len} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    
    # Clean data again
    df_clean = clean_infinity_and_extreme_values(df_clean)
    
    # Balance data for proper anomaly detection
    anomaly_count = len(df_clean[df_clean['is_anomaly'] == 1])
    normal_count = len(df_clean[df_clean['is_anomaly'] == 0])
    
    print(f"üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏î‡∏∏‡∏•:")
    print(f"   - ‡∏õ‡∏Å‡∏ï‡∏¥: {normal_count} ({normal_count/(normal_count+anomaly_count)*100:.1f}%)")
    print(f"   - ‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥: {anomaly_count} ({anomaly_count/(normal_count+anomaly_count)*100:.1f}%)")
    
    # Target ratio 90:10 for proper anomaly detection
    target_ratio = 9.0  # 90% normal, 10% anomaly
    current_ratio = normal_count / anomaly_count if anomaly_count > 0 else float('inf')
    
    if current_ratio < target_ratio * 0.7:  # Too many anomalies
        # Reduce anomaly samples
        anomaly_data = df_clean[df_clean['is_anomaly'] == 1]
        target_anomaly_count = int(normal_count / target_ratio)
        
        if target_anomaly_count < anomaly_count and target_anomaly_count > 0:
            anomaly_sample = anomaly_data.sample(n=target_anomaly_count, random_state=42)
            normal_data = df_clean[df_clean['is_anomaly'] == 0]
            df_clean = pd.concat([normal_data, anomaly_sample], ignore_index=True)
            
            logger.info(f"‡∏õ‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô 90:10")
    
    final_normal = len(df_clean[df_clean['is_anomaly'] == 0])
    final_anomaly = len(df_clean[df_clean['is_anomaly'] == 1])
    
    print(f"\nüìä ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢:")
    print(f"   - ‡∏õ‡∏Å‡∏ï‡∏¥: {final_normal} ({final_normal/(final_normal+final_anomaly)*100:.1f}%)")
    print(f"   - ‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥: {final_anomaly} ({final_anomaly/(final_normal+final_anomaly)*100:.1f}%)")
    print(f"   - Ratio: {final_normal/final_anomaly:.1f}:1")
    
    # Shuffle data
    df_final = df_clean.sample(frac=1, random_state=42).reset_index(drop=True)
    
    # Final safety check
    df_final = clean_infinity_and_extreme_values(df_final)
    
    logger.info(f"‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢: {len(df_final)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    return df_final

def hyperparameter_optimization(X_train, y_train, anomaly_detector):
    """Optimize hyperparameters for TRUE anomaly detection"""
    print("\nüéØ ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á hyperparameters ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Anomaly Detection...")
    
    if not safe_preprocessing_check(X_train, "training data"):
        logger.error("‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏°‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ - ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á")
        return {}
    
    # Calculate actual contamination
    contamination = len(y_train[y_train == 1]) / len(y_train)
    
    logger.info(f"üìä Contamination rate: {contamination:.3f}")
    
    # FIXED: Proper parameters for anomaly detection
    optimized_params = {
        'isolation_forest': {
            'n_estimators': 300,
            'max_samples': 'auto',
            'contamination': min(0.12, max(0.03, contamination * 0.8)),  # ‡∏•‡∏î‡∏•‡∏á
            'max_features': 1.0,
            'bootstrap': False,
            'random_state': 42
        },
        'one_class_svm': {
            'nu': min(0.08, max(0.01, contamination * 0.4)),  # ‡∏•‡∏î‡∏•‡∏á‡∏°‡∏≤‡∏Å
            'gamma': 'scale',
            'kernel': 'rbf',
            'shrinking': True,
            'tol': 1e-3
        },
        'local_outlier_factor': {
            'n_neighbors': 20,
            'contamination': min(0.12, max(0.03, contamination * 0.8)),
            'novelty': True
        },
        'elliptic_envelope': {
            'contamination': min(0.12, max(0.03, contamination * 0.8)),
            'support_fraction': None,
            'random_state': 42
        },
        'random_forest': {
            'n_estimators': 200,
            'max_depth': 12,
            'min_samples_split': 5,
            'min_samples_leaf': 2,
            'class_weight': 'balanced',
            'random_state': 42
        },
        'gradient_boosting': {
            'n_estimators': 150,
            'learning_rate': 0.1,
            'max_depth': 6,
            'min_samples_split': 5,
            'subsample': 0.8,
            'random_state': 42
        }
    }
    
    logger.info(f"‚úÖ ‡πÉ‡∏ä‡πâ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß")
    return optimized_params

def train_and_evaluate_models(df):
    """Train and evaluate models with FIXED parameters"""
    print("\nüöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (ML Optimized)...")
    
    # Prepare data
    anomaly_detector = AnomalyDetectionModels()
    
    try:
        df_prepared, feature_columns = anomaly_detector.prepare_data(df)
        
        if len(feature_columns) == 0:
            raise ValueError("‡πÑ‡∏°‡πà‡∏°‡∏µ features ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ")
        
        logger.info(f"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô features: {len(feature_columns)}")
        
    except Exception as e:
        logger.error(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
        raise
    
    # Extract features and labels
    X = df_prepared[feature_columns].values
    y = df_prepared['is_anomaly'].values
    
    # Clean features data
    print("üßπ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î features...")
    X = np.where(np.isnan(X), 0, X)
    X = np.where(np.isinf(X), 0, X)
    
    # Clip values to safe range
    safe_max = np.finfo(np.float32).max / 1000
    X = np.clip(X, -safe_max, safe_max)
    
    # Final safety check
    if not safe_preprocessing_check(X, "processed features"):
        raise ValueError("‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• features ‡πÑ‡∏°‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô")
    
    print(f"‚úÖ Features: {len(feature_columns)} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå")
    print(f"‚úÖ ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {X.shape}")
    print(f"‚úÖ ‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏≤: {X.min():.3f} ‡∏ñ‡∏∂‡∏á {X.max():.3f}")
    
    # Split data
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, test_size=0.20, random_state=42, stratify=y
    )
    
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=0.20, random_state=42, stratify=y_temp
    )
    
    print(f"\nüìä ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:")
    print(f"   - Training: {len(X_train)} records")
    print(f"   - Validation: {len(X_val)} records")
    print(f"   - Test: {len(X_test)} records")
    print(f"     ‚Ä¢ Normal: {len(y_test[y_test == 0])}")
    print(f"     ‚Ä¢ Anomaly: {len(y_test[y_test == 1])}")
    
    # Get optimized parameters
    best_params = hyperparameter_optimization(X_train, y_train, anomaly_detector)
    
    results = {}
    
    # UPDATED: Train supervised models first (better for labeled data)
    models_to_train = [
        ('random_forest', 'Random Forest (Supervised)'),
        ('gradient_boosting', 'Gradient Boosting (Supervised)'),
        ('isolation_forest', 'Isolation Forest'),
        ('one_class_svm', 'One-Class SVM'),
        ('local_outlier_factor', 'Local Outlier Factor'),
        ('elliptic_envelope', 'Elliptic Envelope'),
        ('ensemble', 'Ensemble Model')
    ]
    
    successful_models = []
    
    for model_name, model_display_name in models_to_train:
        try:
            print(f"\nü§ñ Training {model_display_name}...")
            
            # Train supervised models
            if model_name == 'random_forest':
                from sklearn.ensemble import RandomForestClassifier
                params = best_params.get('random_forest', {})
                rf_model = RandomForestClassifier(**params)
                rf_model.fit(X_train, y_train)
                
                # Store in detector
                if not hasattr(anomaly_detector, 'models'):
                    anomaly_detector.models = {}
                anomaly_detector.models['random_forest'] = rf_model
                
            elif model_name == 'gradient_boosting':
                from sklearn.ensemble import GradientBoostingClassifier
                params = best_params.get('gradient_boosting', {})
                gb_model = GradientBoostingClassifier(**params)
                gb_model.fit(X_train, y_train)
                
                if not hasattr(anomaly_detector, 'models'):
                    anomaly_detector.models = {}
                anomaly_detector.models['gradient_boosting'] = gb_model
                
            # Train unsupervised models with FIXED parameters
            elif model_name == 'isolation_forest':
                if hasattr(anomaly_detector, 'model_config') and 'isolation_forest' in best_params:
                    anomaly_detector.model_config['isolation_forest'].update(best_params['isolation_forest'])
                anomaly_detector.train_isolation_forest_enhanced(X_train, y_train)
                
            elif model_name == 'one_class_svm':
                if hasattr(anomaly_detector, 'model_config') and 'one_class_svm' in best_params:
                    anomaly_detector.model_config['one_class_svm'].update(best_params['one_class_svm'])
                anomaly_detector.train_one_class_svm_enhanced(X_train, y_train)
                
            elif model_name == 'local_outlier_factor':
                if hasattr(anomaly_detector, 'model_config') and 'local_outlier_factor' in best_params:
                    anomaly_detector.model_config['local_outlier_factor'].update(best_params['local_outlier_factor'])
                anomaly_detector.train_local_outlier_factor(X_train, y_train)
                
            elif model_name == 'elliptic_envelope':
                if hasattr(anomaly_detector, 'model_config') and 'elliptic_envelope' in best_params:
                    anomaly_detector.model_config['elliptic_envelope'].update(best_params['elliptic_envelope'])
                anomaly_detector.train_elliptic_envelope(X_train, y_train)
                
            elif model_name == 'ensemble':
                anomaly_detector.train_ensemble_model(X_train, y_train)
            
            # Evaluate model
            val_results = anomaly_detector.evaluate_model_enhanced(X_val, y_val, model_name)
            test_results = anomaly_detector.evaluate_model_enhanced(X_test, y_test, model_name)
            
            # Check results
            val_f1 = val_results.get('f1_score', 0)
            test_f1 = test_results.get('f1_score', 0)
            
            if val_f1 > 0.05 or test_f1 > 0.05:  # Model works
                results[model_name] = {
                    'validation': val_results,
                    'test': test_results,
                    'best_params': best_params.get(model_name, {})
                }
                successful_models.append(model_name)
                
                logger.info(f"‚úÖ {model_display_name} trained successfully")
                logger.info(f"   Validation F1: {val_f1:.4f}")
                logger.info(f"   Test F1: {test_f1:.4f}")
            else:
                logger.warning(f"‚ö†Ô∏è  {model_display_name} F1-score ‡∏ï‡πà‡∏≥")
                
        except Exception as e:
            logger.error(f"‚ùå Error training {model_display_name}: {e}")
            continue
    
    if len(successful_models) == 0:
        logger.warning("‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ")
        return results, anomaly_detector
    
    print(f"\n‚úÖ ‡πÄ‡∏ó‡∏£‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(successful_models)}/{len(models_to_train)} ‡πÇ‡∏°‡πÄ‡∏î‡∏•")
    print(f"   Models: {', '.join(successful_models)}")
    
    # Save models
    print("\nüíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
    anomaly_detector.save_models_enhanced("models/anomaly_detection")
    logger.info("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
    
    return results, anomaly_detector

def test_rule_based_detection():
    """Test Rule-based Detection"""
    print("\nüîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Rule-based Anomaly Detection...")
    
    rule_detector = RuleBasedAnomalyDetector()
    
    test_cases = [
        {
            'name': '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏Å‡∏ï‡∏¥',
            'data': {
                'temperature': 25.5,
                'humidity': 64.2,
                'vpd': 1.18,
                'voltage': 3.31,
                'battery_level': 84,
                'timestamp': datetime.now().isoformat()
            }
        },
        {
            'name': '‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î‡∏™‡∏π‡∏á',
            'data': {
                'temperature': 17.5,
                'humidity': 97.0,
                'vpd': 0.25,
                'voltage': 3.25,
                'timestamp': datetime.now().isoformat()
            }
        }
    ]
    
    for test_case in test_cases:
        print(f"\n   {test_case['name']}:")
        
        try:
            anomalies = rule_detector.detect_anomalies([test_case['data']])
            
            if anomalies:
                print(f"      ‚ö†Ô∏è  ‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥: {len(anomalies)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            else:
                print("      ‚úÖ ‡∏õ‡∏Å‡∏ï‡∏¥")
        except Exception as e:
            logger.error(f"‚ùå Error: {e}")
    
    logger.info("‚úÖ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Rule-based Detection ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")

def create_performance_visualization(results):
    """Create performance visualization"""
    if not results:
        print("‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü")
        return
    
    try:
        print("\nüìä ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û...")
        
        os.makedirs("plots", exist_ok=True)
        
        plt.style.use('default')
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Model Performance - ML Optimized', fontsize=16, fontweight='bold')
        
        models = list(results.keys())
        
        # Prepare metrics
        metrics = {
            'F1-Score': [],
            'Precision': [],
            'Recall': [],
            'Accuracy': []
        }
        
        for model in models:
            try:
                test_result = results[model]['test']
                
                f1 = test_result.get('f1_score', 0)
                precision = test_result.get('precision', 0)
                recall = test_result.get('recall', 0)
                
                cm = test_result.get('confusion_matrix')
                if cm is not None and cm.size >= 4:
                    tn, fp, fn, tp = cm.ravel()
                    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0
                else:
                    accuracy = 0
                
                metrics['F1-Score'].append(f1)
                metrics['Precision'].append(precision)
                metrics['Recall'].append(recall)
                metrics['Accuracy'].append(accuracy)
                
            except Exception as e:
                for metric in metrics.keys():
                    metrics[metric].append(0)
        
        colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']
        
        for i, (metric_name, values) in enumerate(metrics.items()):
            row, col = i // 2, i % 2
            ax = axes[row, col]
            
            bars = ax.bar(models, values, color=colors[i], alpha=0.7, edgecolor='black')
            ax.set_title(f'{metric_name}', fontweight='bold')
            ax.set_ylabel(metric_name)
            ax.set_ylim(0, 1.05)
            ax.tick_params(axis='x', rotation=45)
            ax.grid(axis='y', alpha=0.3)
            
            for bar, value in zip(bars, values):
                if value > 0:
                    ax.text(bar.get_x() + bar.get_width()/2, value + 0.02, 
                           f'{value:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=8)
        
        plt.tight_layout()
        plt.savefig('plots/model_performance_optimized.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("‚úÖ ‡∏Å‡∏£‡∏≤‡∏ü‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà: plots/model_performance_optimized.png")
        
    except Exception as e:
        logger.error(f"‚ùå Error creating visualization: {e}")

def display_results_summary(results):
    """Display enhanced results summary"""
    print("\n" + "="*80)
    print("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• - ML Optimized")
    print("="*80)
    
    if not results:
        print("‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô")
        return
    
    best_f1 = 0
    best_model = None
    
    for model_name, result in results.items():
        try:
            test_result = result['test']
            val_result = result['validation']
            
            test_f1 = test_result.get('f1_score', 0)
            test_precision = test_result.get('precision', 0)
            test_recall = test_result.get('recall', 0)
            val_f1 = val_result.get('f1_score', 0)
            
            if test_f1 > best_f1:
                best_f1 = test_f1
                best_model = model_name
            
            overfitting = abs(val_f1 - test_f1)
            
            print(f"\nü§ñ {model_name.replace('_', ' ').upper()}:")
            print(f"   Test F1-Score: {test_f1:.4f}")
            print(f"   Test Precision: {test_precision:.4f}")
            print(f"   Test Recall: {test_recall:.4f}")
            print(f"   Validation F1: {val_f1:.4f}")
            print(f"   Overfitting: {overfitting:.4f}")
                
        except Exception as e:
            logger.error(f"‚ùå Error displaying {model_name}: {e}")
            continue
    
    print(f"\n{'='*80}")
    print("üìà ‡∏™‡∏£‡∏∏‡∏õ:")
    if best_model and best_f1 > 0:
        print(f"   ‚≠ê ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {best_model.replace('_', ' ').title()}")
        print(f"   üìä F1-Score: {best_f1:.4f}")
        
        if best_f1 > 0.70:
            print("   ‚úÖ ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏° - ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        elif best_f1 > 0.50:
            print("   ‚úÖ ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏î‡∏µ - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ")
        else:
            print("   ‚ö†Ô∏è  ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Rules")
    else:
        print("   ‚ö†Ô∏è  ‡πÉ‡∏ä‡πâ Rule-based Detection")
    print("="*80)

def save_training_info(results, detector):
    """Save training information"""
    try:
        training_summary = {
            'training_date': datetime.now().isoformat(),
            'model_type': 'anomaly_detection_ml_optimized',
            'total_models': len(results),
            'successful_models': len([r for r in results.values() if r['test'].get('f1_score', 0) > 0.05]),
            'best_model': '',
            'best_test_f1_score': 0,
            'model_performance': {},
            'feature_info': {
                'total_features': len(getattr(detector, 'feature_columns', []) + 
                                    getattr(detector, 'time_features', []) + 
                                    getattr(detector, 'derived_features', [])),
                'base_features': len(getattr(detector, 'feature_columns', [])),
                'derived_features': len(getattr(detector, 'derived_features', []))
            },
            'training_config': {
                'data_ratio': '90-92% normal, 8-10% anomaly',
                'data_splitting': '64% train, 16% validation, 20% test',
                'optimization': 'ML-optimized parameters for anomaly detection',
                'models': 'Supervised + Unsupervised ensemble'
            }
        }
        
        for model_name, result in results.items():
            try:
                test_result = result['test']
                test_f1 = test_result.get('f1_score', 0)
                
                training_summary['model_performance'][model_name] = {
                    'test_f1_score': test_f1,
                    'test_precision': test_result.get('precision', 0),
                    'test_recall': test_result.get('recall', 0),
                    'test_specificity': test_result.get('specificity', 0)
                }
                
                if test_f1 > training_summary['best_test_f1_score']:
                    training_summary['best_test_f1_score'] = test_f1
                    training_summary['best_model'] = model_name
                    
            except Exception as e:
                continue
        
        os.makedirs('models', exist_ok=True)
        with open('models/training_summary_optimized.json', 'w', encoding='utf-8') as f:
            json.dump(training_summary, f, indent=2, ensure_ascii=False)
        
        logger.info("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        
    except Exception as e:
        logger.error(f"‚ùå Error saving training info: {e}")

def main():
    """Main training function - ML Optimized"""
    print("="*80)
    print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Anomaly Detection - ML OPTIMIZED")
    print("="*80)
    print("\nüìå ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á:")
    print("   ‚úÖ ‡∏õ‡∏£‡∏±‡∏ö data ratio ‡πÄ‡∏õ‡πá‡∏ô 90:10 (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö anomaly detection)")
    print("   ‚úÖ ‡∏•‡∏î contamination parameters")
    print("   ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° Supervised models (Random Forest, Gradient Boosting)")
    print("   ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (365 ‡∏ß‡∏±‡∏ô)")
    print("\n" + "="*80)
    
    for directory in ["data", "models", "plots"]:
        os.makedirs(directory, exist_ok=True)
    
    try:
        # 1. Load and clean data
        print("\n[1/6] üìÇ ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        df = load_or_generate_data(force_generate=True)
        
        print(f"\nüìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(df)} records")
        normal_count = len(df[df['is_anomaly'] == 0])
        anomaly_count = len(df[df['is_anomaly'] == 1])
        print(f"   - Normal: {normal_count} ({normal_count/len(df)*100:.1f}%)")
        print(f"   - Anomaly: {anomaly_count} ({anomaly_count/len(df)*100:.1f}%)")
        print(f"   - Ratio: {normal_count/anomaly_count:.1f}:1")
        
        # 2. Validate data quality
        print("\n[2/6] üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        data_quality_ok = validate_data_quality(df)
        if not data_quality_ok:
            logger.warning("‚ö†Ô∏è  ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå ‡πÅ‡∏ï‡πà‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠")
        
        # 3. Prepare training data
        print("\n[3/6] ‚öôÔ∏è  ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô...")
        df_clean = prepare_training_data(df)
        
        if len(df_clean) < 100:
            raise ValueError("‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô")
        
        # 4. Train and evaluate models
        print("\n[4/6] ü§ñ ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
        results, detector = train_and_evaluate_models(df_clean)
        
        # 5. Test rule-based detection
        print("\n[5/6] üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Rule-based Detection...")
        test_rule_based_detection()
        
        # 6. Create visualization and summary
        print("\n[6/6] üìä ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•...")
        create_performance_visualization(results)
        display_results_summary(results)
        save_training_info(results, detector)
        
        print(f"\n{'='*80}")
        print("‚úÖ ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ML OPTIMIZED ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
        print("="*80)
        print("\nüìÅ ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á:")
        print("   üìÑ models/anomaly_detection_*.pkl")
        print("   üìÑ models/training_summary_optimized.json")
        print("   üìÑ data/sensor_training_data.csv")
        print("   üìÑ plots/model_performance_optimized.png")
        print("   üìÑ training.log")
        
        # Show final summary
        if results:
            working_models = [k for k, v in results.items() if v['test'].get('f1_score', 0) > 0.1]
            
            if working_models:
                best_model = max(working_models, 
                               key=lambda x: results[x]['test'].get('f1_score', 0))
                best_f1 = results[best_model]['test'].get('f1_score', 0)
                
                print(f"\n{'='*80}")
                print("üèÜ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢")
                print("="*80)
                print(f"   ‚≠ê ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {best_model.replace('_', ' ').title()}")
                print(f"   üìä Test F1-Score: {best_f1:.4f}")
                print(f"   ‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ: {len(working_models)}/{len(results)}")
                
                # Calculate average F1
                avg_f1 = np.mean([results[m]['test'].get('f1_score', 0) for m in working_models])
                print(f"   üìà F1-Score ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {avg_f1:.4f}")
                
                if best_f1 > 0.7:
                    print("\n   üéâ ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á!")
                elif best_f1 > 0.5:
                    print("\n   ‚úÖ ‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Rules")
                else:
                    print("\n   ‚ö†Ô∏è  ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ä‡πâ Hybrid (ML + Rules)")
                    
            else:
                print("\n‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏• ML ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ")
                print("   üí° ‡πÉ‡∏ä‡πâ Rule-based Detection ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
        
        print("="*80)
        logger.info("‚úÖ ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ML OPTIMIZED ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå")
        
        return detector, results
        
    except Exception as e:
        logger.error(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô: {e}")
        print(f"\n{'='*80}")
        print("‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î!")
        print("="*80)
        print(f"Error: {e}")
        print("\nüí° ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:")
        print("   1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• input")
        print("   2. ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏≥‡∏ô‡∏ß‡∏ô features")
        print("   3. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö memory ‡πÅ‡∏•‡∏∞ system resources")
        print("   4. ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Rule-based detection")
        raise

if __name__ == "__main__":
    try:
        print("\n" + "="*80)
        print("   üå± EMIB Smart Farming - ML Model Training")
        print("   üìÖ " + datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        print("="*80 + "\n")
        
        detector, results = main()
        
        # Final statistics
        if results:
            working_models = [k for k, v in results.items() if v['test'].get('f1_score', 0) > 0.1]
            
            print("\n" + "="*80)
            print("üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢")
            print("="*80)
            print(f"   ‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ: {len(working_models)}/{len(results)}")
            
            if working_models:
                avg_f1 = np.mean([results[m]['test'].get('f1_score', 0) for m in working_models])
                max_f1 = max([results[m]['test'].get('f1_score', 0) for m in working_models])
                min_f1 = min([results[m]['test'].get('f1_score', 0) for m in working_models])
                
                print(f"   üìà F1-Score:")
                print(f"      - ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {max_f1:.4f}")
                print(f"      - ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {avg_f1:.4f}")
                print(f"      - ‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î: {min_f1:.4f}")
                print("\n   üéâ ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
            else:
                print("   ‚ö†Ô∏è  ‡πÉ‡∏ä‡πâ Rule-based detection ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
            
            print("="*80)
        
        print("\n‚úÖ Training completed successfully!")
        print("üí° Run 'python test_system.py' to test the models\n")
            
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏ñ‡∏π‡∏Å‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡πÇ‡∏î‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ")
        logger.info("Training interrupted by user")
    except Exception as e:
        print(f"\n‚ùå ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")
        logger.error(f"Training failed: {e}")
        print("\nüí° ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: python anomaly_api.py ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö Rule-based detection")